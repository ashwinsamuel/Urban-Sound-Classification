{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jackhammer          0.122907\n",
       "engine_idling       0.114811\n",
       "siren               0.111684\n",
       "drilling            0.110396\n",
       "dog_bark            0.110396\n",
       "air_conditioner     0.110396\n",
       "children_playing    0.110396\n",
       "street_music        0.110396\n",
       "car_horn            0.056302\n",
       "gun_shot            0.042318\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir='C:/Users/ashwin.s/Documents/Urban Sound Classification/Data' \n",
    "train = pd.read_csv(os.path.join(data_dir, 'train_1.csv'))\n",
    "\n",
    "train.Class.value_counts(normalize=True)\n",
    "\n",
    "#train=train.values\n",
    "#print(train[0],train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += (window_size / 2)\n",
    "        \n",
    "def extract_features(filename, bands = 60, frames = 41):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    log_specgrams = []\n",
    "    sound_clip,s = librosa.load(filename)        \n",
    "    \n",
    "    \n",
    "    if(len(sound_clip)<window_size):\n",
    "        sound_clip,s=librosa.load(filename,sr=22050*math.ceil(window_size/len(sound_clip)))\n",
    "    \n",
    "    \n",
    "    for (start,end) in windows(sound_clip,window_size):\n",
    "            start = int(start)\n",
    "            end = int(end)\n",
    "            if(len(sound_clip[start:end]) == window_size):\n",
    "                signal = sound_clip[start:end]\n",
    "                melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "                logspec = librosa.amplitude_to_db(melspec)\n",
    "                logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                log_specgrams.append(logspec)\n",
    "    \n",
    "    log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis = 3)\n",
    "    for i in range(len(features)):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_features(df,data_dir):#labels\n",
    "    fea=np.empty((0,60,41,2))\n",
    "    labels=[]\n",
    "    \n",
    "    for i in range (df.shape[0]):\n",
    "        filename=os.path.join(data_dir,str(df[i][0])+'.wav')\n",
    "        label=df[i][1]\n",
    "    \n",
    "        feature = extract_features(filename)\n",
    "        \n",
    "        for j in range(feature.shape[0]):\n",
    "            labels.append(label)\n",
    "            \n",
    "        fea=np.concatenate((fea,feature),axis=0)\n",
    "   \n",
    "    return fea,labels\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33850, 60, 41, 2) 33850\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "data_dir='C:/Users/ashwin.s/Documents/Urban Sound Classification/Data' \n",
    "#train=pd.read_csv(os.path.join(data_dir, 'train_2.csv'))\n",
    "\n",
    "dir1 ='C:/Users/ashwin.s/Documents/Urban Sound Classification/Data/Train'\n",
    "      \n",
    "\n",
    "train=train.values\n",
    "\n",
    "cnnX,cnnY=save_features(train,dir1)\n",
    "print(cnnX.shape,len(cnnY))\n",
    "\n",
    "\n",
    "with open('cnnX.pickle', 'wb') as handle:\n",
    "     pickle.dump(cnnX, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "with open('cnnY.pickle', 'wb') as handle:\n",
    "     pickle.dump(cnnY, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashwin.s\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] (33850, 10) (33850, 60, 41, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "import pickle\n",
    "\n",
    "with open('cnnX.pickle','rb') as handle:\n",
    "     cnnX=pickle.load(handle)\n",
    "with open('cnnY.pickle','rb') as handle:\n",
    "     cnnY=pickle.load(handle)\n",
    "\n",
    "\n",
    "lb=LabelEncoder();\n",
    "\n",
    "cnnY=np_utils.to_categorical(lb.fit_transform(cnnY))\n",
    "print(cnnY[0],cnnY.shape,cnnX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    # input: 60x41 data frames with 2 channels => (60,41,2) tensors\n",
    "\n",
    "    # filters of size 1x1 \n",
    "    f_size = 1\n",
    "\n",
    "    # first layer has 48 convolution filters \n",
    "    model.add(Convolution2D(48, f_size, strides=f_size, kernel_initializer='normal', padding='same', input_shape=(60, 41, 2)))\n",
    "    model.add(Convolution2D(48, f_size, strides=f_size, kernel_initializer='normal', padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # next layer has 96 convolution filters\n",
    "    model.add(Convolution2D(96, f_size, strides=f_size, kernel_initializer='normal', padding='same'))\n",
    "    model.add(Convolution2D(96, f_size, strides=f_size, kernel_initializer='normal', padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # flatten output into a single dimension \n",
    "    # Keras will do shape inference automatically\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # then a fully connected NN layer\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # finally, an output layer with one node per class\n",
    "    model.add(Dense(cnnY.shape[1]))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # use the Adam optimiser\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 32834 samples, validate on 1016 samples\n",
      "Epoch 1/150\n",
      "32834/32834 [==============================] - 282s 9ms/step - loss: 1.6983 - acc: 0.3893 - val_loss: 1.3594 - val_acc: 0.5276\n",
      "Epoch 2/150\n",
      "32834/32834 [==============================] - 297s 9ms/step - loss: 1.3282 - acc: 0.5356 - val_loss: 1.2338 - val_acc: 0.6260\n",
      "Epoch 3/150\n",
      "32834/32834 [==============================] - 302s 9ms/step - loss: 1.1787 - acc: 0.5898 - val_loss: 1.0843 - val_acc: 0.6752\n",
      "Epoch 4/150\n",
      "32834/32834 [==============================] - 302s 9ms/step - loss: 1.0836 - acc: 0.6250 - val_loss: 0.9583 - val_acc: 0.7067\n",
      "Epoch 5/150\n",
      "32834/32834 [==============================] - 343s 10ms/step - loss: 1.0244 - acc: 0.6479 - val_loss: 0.9873 - val_acc: 0.6969\n",
      "Epoch 6/150\n",
      "32834/32834 [==============================] - 344s 10ms/step - loss: 0.9704 - acc: 0.6640 - val_loss: 0.9071 - val_acc: 0.7352\n",
      "Epoch 7/150\n",
      "32834/32834 [==============================] - 335s 10ms/step - loss: 0.9334 - acc: 0.6767 - val_loss: 0.9620 - val_acc: 0.7037\n",
      "Epoch 8/150\n",
      "32834/32834 [==============================] - 292s 9ms/step - loss: 0.9045 - acc: 0.6863 - val_loss: 0.8854 - val_acc: 0.7264\n",
      "Epoch 9/150\n",
      "32834/32834 [==============================] - 303s 9ms/step - loss: 0.8785 - acc: 0.6963 - val_loss: 0.8094 - val_acc: 0.7323\n",
      "Epoch 10/150\n",
      "32834/32834 [==============================] - 303s 9ms/step - loss: 0.8614 - acc: 0.7030 - val_loss: 0.8065 - val_acc: 0.7608\n",
      "Epoch 11/150\n",
      "32834/32834 [==============================] - 303s 9ms/step - loss: 0.8418 - acc: 0.7092 - val_loss: 0.8493 - val_acc: 0.7372\n",
      "Epoch 12/150\n",
      "32834/32834 [==============================] - 304s 9ms/step - loss: 0.8175 - acc: 0.7159 - val_loss: 0.8286 - val_acc: 0.7421\n",
      "Epoch 13/150\n",
      "32834/32834 [==============================] - 303s 9ms/step - loss: 0.8051 - acc: 0.7188 - val_loss: 0.8599 - val_acc: 0.7382\n",
      "Epoch 14/150\n",
      "32834/32834 [==============================] - 303s 9ms/step - loss: 0.7934 - acc: 0.7237 - val_loss: 0.7705 - val_acc: 0.7648\n",
      "Epoch 15/150\n",
      "32834/32834 [==============================] - 308s 9ms/step - loss: 0.7781 - acc: 0.7291 - val_loss: 0.7753 - val_acc: 0.7520\n",
      "Epoch 16/150\n",
      "32834/32834 [==============================] - 312s 10ms/step - loss: 0.7642 - acc: 0.7341 - val_loss: 0.7845 - val_acc: 0.7490\n",
      "Epoch 17/150\n",
      "32834/32834 [==============================] - 312s 10ms/step - loss: 0.7606 - acc: 0.7340 - val_loss: 0.7319 - val_acc: 0.7598\n",
      "Epoch 18/150\n",
      "32834/32834 [==============================] - 311s 9ms/step - loss: 0.7382 - acc: 0.7420 - val_loss: 0.7457 - val_acc: 0.7372\n",
      "Epoch 19/150\n",
      "32834/32834 [==============================] - 314s 10ms/step - loss: 0.7433 - acc: 0.7399 - val_loss: 0.7736 - val_acc: 0.7470\n",
      "Epoch 20/150\n",
      "32834/32834 [==============================] - 313s 10ms/step - loss: 0.7248 - acc: 0.7472 - val_loss: 0.6843 - val_acc: 0.7805\n",
      "Epoch 21/150\n",
      "32834/32834 [==============================] - 313s 10ms/step - loss: 0.7204 - acc: 0.7501 - val_loss: 0.7658 - val_acc: 0.7667\n",
      "Epoch 22/150\n",
      "32834/32834 [==============================] - 316s 10ms/step - loss: 0.7179 - acc: 0.7524 - val_loss: 0.7080 - val_acc: 0.7835\n",
      "Epoch 23/150\n",
      "32834/32834 [==============================] - 346s 11ms/step - loss: 0.7047 - acc: 0.7531 - val_loss: 0.7060 - val_acc: 0.7628\n",
      "Epoch 24/150\n",
      "32834/32834 [==============================] - 337s 10ms/step - loss: 0.6947 - acc: 0.7578 - val_loss: 0.6822 - val_acc: 0.7953\n",
      "Epoch 25/150\n",
      "32834/32834 [==============================] - 357s 11ms/step - loss: 0.6855 - acc: 0.7604 - val_loss: 0.7986 - val_acc: 0.7549\n",
      "Epoch 26/150\n",
      "32834/32834 [==============================] - 315s 10ms/step - loss: 0.6863 - acc: 0.7590 - val_loss: 0.6989 - val_acc: 0.7844\n",
      "Epoch 27/150\n",
      "  420/32834 [..............................] - ETA: 5:05 - loss: 0.7809 - acc: 0.7095"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1a7e956297cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# now fit the model to the training data, evaluating loss against the validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training model...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnnX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnnY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.03\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "# a stopping function to stop training before we excessively overfit to the training set\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "\n",
    "# now fit the model to the training data, evaluating loss against the validation data\n",
    "print(\"Training model...\")\n",
    "history=model.fit(cnnX, cnnY, batch_size=20, epochs=150,validation_split=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-88cc0106fd3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_features(df,data_dir):#labels\n",
    "    fea=[]\n",
    "    id=[]\n",
    "    \n",
    "    for i in range (df.shape[0]):\n",
    "        filename=os.path.join(data_dir,str(df[i][0])+'.wav')\n",
    "    \n",
    "        feature = extract_features(filename)\n",
    "        \n",
    "        fea.append(feature)\n",
    "        id.append(df[i])\n",
    "\n",
    "    return fea,id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-27e366d7568b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcnnX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcnnY_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdir_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnnX_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcnnX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnnY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-8907e1695a64>\u001b[0m in \u001b[0;36mtest_features\u001b[1;34m(df, data_dir)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mfea\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-9a6b78f6eccd>\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(filename, bands, frames)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mwindow_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mlog_specgrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0msound_clip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     '''\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\resampy\\core.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0mresample_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "dir_test='C:/Users/ashwin.s/Documents/Urban Sound Classification/Data/Test'\n",
    "\n",
    "test = pd.read_csv(os.path.join(data_dir, 'test_data.csv'))\n",
    "test=test.values\n",
    "\n",
    "cnnX_test,cnnY_test=test_features(test,dir_test)\n",
    "print(len(cnnX_test) , cnnX_test[0].shape , len(cnnY_test))\n",
    "\n",
    "\n",
    "with open('cnnX_test.pickle', 'wb') as handle:\n",
    "     pickle.dump(cnnX_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "with open('cnnY_test.pickle', 'wb') as handle:\n",
    "     pickle.dump(cnnY_test, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3297 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('cnnX_test.pickle','rb') as handle:\n",
    "     cnnX_test=pickle.load(handle)\n",
    "with open('cnnY_test.pickle','rb') as handle:\n",
    "     cnnY_test=pickle.load(handle)\n",
    "\n",
    "labels=[]\n",
    "id=[]\n",
    "for i in range (len(cnnX_test)):\n",
    "    feature=cnnX_test[i]\n",
    "    l=np.zeros((10,))\n",
    "    \n",
    "    #print(feature.shape)\n",
    "    for j in range(feature.shape[0]):\n",
    "        #print(j)\n",
    "        fea=feature[j].reshape(1,60,41,2)\n",
    "        result=model.predict(fea)\n",
    "        result=result.argmax(axis=-1)\n",
    "        l[result]+=1\n",
    "    l=l.argmax(axis=-1)\n",
    "    labels.append(l)\n",
    "    id.append(cnnY_test[i][0])\n",
    "    \n",
    "print(len(labels) , labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={\n",
    "    0:'air_conditioner',\n",
    "    1:'car_horn',\n",
    "    2:'children_playing',\n",
    "    3:'dog_bark',\n",
    "    4:'drilling',\n",
    "    5:'engine_idling',\n",
    "    6:'gun_shot',\n",
    "    7:'jackhammer',\n",
    "    8:'siren',\n",
    "    9:'street_music',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "resultL=[]\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    resultL.append(d[labels[i]])\n",
    "\n",
    "temp2 = pd.DataFrame(\n",
    "    {\n",
    "     'Class': resultL,\n",
    "     'ID': id,\n",
    "    })\n",
    "\n",
    "temp2.to_csv('C:/Users/ashwin.s/Documents/Urban Sound Classification/Data/result_CNN.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
